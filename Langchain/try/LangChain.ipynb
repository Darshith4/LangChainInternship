{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DOycdBmh0FBf"
      },
      "source": [
        "Copyright Â© 2023 Patrick Loeber"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nTDgRy0jKDkP"
      },
      "source": [
        "# LangChain\n",
        "\n",
        "LangChain is a framework for developing applications powered by language models.\n",
        "\n",
        "- GitHub: https://github.com/hwchase17/langchain\n",
        "- Docs: https://python.langchain.com/en/latest/index.html\n",
        "\n",
        "### Overview:\n",
        "- Installation\n",
        "- LLMs\n",
        "- Prompt Templates\n",
        "- Chains\n",
        "- Agents and Tools\n",
        "- Memory\n",
        "- Document Loaders\n",
        "- Indexes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5WGtOYYTKfz3"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bcrn7QRyQXGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.0.199)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (2.28.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: langchainplus-sdk>=0.0.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (0.0.9)\n",
            "Requirement already satisfied: numpy<2,>=1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (0.5.8)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (22.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NkGGSdmtta6s"
      },
      "source": [
        "## 1. LLMs\n",
        "\n",
        "A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "H_dfy6G_aBtY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (2.28.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RlxEmS1CaM5v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "c:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\langchain\\llms\\openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "India won the 2011 cricket World Cup and Mahendra Singh Dhoni scored the winning runs.\n",
            "The number of character in the prompt response is, 86!\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo\")  \n",
        "text = \"Who won the cricket 2011 World cup and who scored the winning runs?\"\n",
        "\n",
        "output1 = llm(text)\n",
        "print(output1)\n",
        "length = len(output1)\n",
        "print(f\"The number of character in the prompt response is, {length}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "pY09s9cmZ6nQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Functional Requirements:\n",
            "1. Real-time notifications and updates on delays, cancellations, and alternative routes in a pro-active manner.\n",
            "2. User-friendly and personalised messaging system that alerts the users on any commuter-related activity.\n",
            "3. Integration of a centralised information system to provide continuous updates on schedules and delays for the commuters.\n",
            "4. A learning algorithm that analyses user behaviour to provide personalised and customized solutions.\n",
            "5. Integration with the major public transportation systems.\n",
            "6. Voice-activated commands for use while commuting.\n",
            "7. Integration of payment methods to purchase tickets through the app.\n",
            "8. Integration with traffic and weather data to alert users of route changes due to these factors.\n",
            "9. Option to plan journey in advance and receive reminders and alerts before the journey.\n",
            "\n",
            "Usability Requirements:\n",
            "1. Responsive design to allow for smooth functioning on different screen sizes and devices, including mobile phones, tablets and desktops.\n",
            "2. User-friendly interface with intuitive features and navigability.\n",
            "3. Multilingual support for wide user accessibility.\n",
            "4. Integration with common accessibility features such as text-to-speech and enlarged fonts.\n",
            "5. Integration of a feedback and rating system to allow users to provide feedback and help improve the app's performance.\n",
            "\n",
            "Reliability Requirements:\n",
            "1. The app should provide reliable and timely information.\n",
            "2. The app should have a high uptime ratio for uninterrupted access.\n",
            "3. The app should be tested for security and accuracy.\n",
            "\n",
            "Performance Requirements:\n",
            "1. The app should have high-speed performance with minimal waiting time for information requests.\n",
            "2. The app should support heavy load traffic without reducing functionality.\n",
            "3. The app should have an offline capability in cases where internet connectivity is unavailable.\n",
            "\n",
            "Supportability Requirements:\n",
            "1. Regular app updates for new features and bug fixes.\n",
            "2. Comprehensive user support system accessible through the app, such as user manuals, FAQs, and online chat.\n",
            "3. Support for multi-platform compatibility such as iOS, Android, and Web.\n",
            "4. Seamless integration with other commonly used apps for commuting, such as ride-sharing apps. \n",
            "\n",
            "Design, Implementation and External Hardware Requirements:\n",
            "1. The app should be scalable to allow for increased user base.\n",
            "2. The app should allow for customisation of display options such as colour schemes and font sizes.\n",
            "3. Integration of push notifications for timely alerts.\n",
            "4. The app should be designed to be lightweight to minimise memory usage and improve device performance.\n",
            "5. Integration with external hardware such as smartwatches for better accessibility.\n",
            "6. The app should be designed to consume minimal bandwidth to enable functionality in areas with slow network connectivity.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo\")  \n",
        "text = \"AI-Based Commuter App Problem or Need. Many public transportation systems across the world have apps with varying degrees of functionality. However, there are not many comprehensive apps that would notify/guide users in real-time in a multitude of scenarios. Several commuters spend a lot of time not only in commuting, but also in waiting for their rides. An information system that would inform and alert users on delays in real-time and on alternative routes in a pro-active manner would be very helpful in saving precious time. The app should work in tandem with a centralized information system that would continuously update and communicate schedules and delays (if any) in real- time. The app can be a constant companion to commuters and alert them/guide them with short and user-friendly messages or through any other user-friendly mode, on any commuter- related activity. The app should not only address the routine functionality and challenges associated with commuting, but also the other major challenges and solutions as you see it. Google may also display alternative routes based on several factors, however this app is meant to learn from user behavior on an ongoing basis in majorly customizing and alerting the user on alternative routes and options in a pro-active manner. Instructions ï· You need to define the Software Requirements Specification for the proposed App using the (FURPS+) framework that includes the specification for:  o Supportability Requirements o Design, Implementation, External Hardware and Physical Constraints ï· A minimum of 9 and a maximum of 12 most important requirements may be included for each category.\"\n",
        "\n",
        "output1 = llm(text)\n",
        "print(output1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idkq_aVyaceF"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4DKOWjyaRmO"
      },
      "outputs": [],
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_HF_TOKEN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmtH72oCaU32"
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uK5TtJPc49I"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/google/flan-t5-xl\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
        "\n",
        "llm(\"translate English to German: How old are you?\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3O-7dO1htdO4"
      },
      "source": [
        "## 2. Prompt Templates\n",
        "\n",
        "LangChain faciliates prompt management and optimization.\n",
        "\n",
        "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FDS9IDRapOt"
      },
      "outputs": [],
      "source": [
        "llm(\"Can Barack Obama have a conversation with George Washington?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB4W8dM1tPAY"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Question: Can Barack Obama have a conversation with George Washington?\n",
        "\n",
        "Let's think step by step.\n",
        "\n",
        "Answer: \"\"\"\n",
        "llm(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU1VyMMvtsCE"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Let's think step by step.\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Yzpc_0aHHeE"
      },
      "outputs": [],
      "source": [
        "prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "on8ubh3kt7oD"
      },
      "outputs": [],
      "source": [
        "llm(prompt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1zw1KlSeuUOY"
      },
      "source": [
        "## 3. Chains\n",
        "\n",
        "Combine LLMs and Prompts in multi-step workflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE6n-jbAuOxt"
      },
      "outputs": [],
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "question = \"Can Barack Obama have a conversation with George Washington?\"\n",
        "\n",
        "print(llm_chain.run(question))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-UlOK0bMVQ"
      },
      "source": [
        "## 4. Agents and Tools\n",
        "\n",
        "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
        "\n",
        "\n",
        "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
        "\n",
        "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
        "- LLM: The language model powering the agent.\n",
        "- Agent: The agent to use.\n",
        "\n",
        "Tools: https://python.langchain.com/en/latest/modules/agents/tools.html\n",
        "\n",
        "Agent Types: https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79JcjhFXwv0J"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOSpaurEb1MR"
      },
      "outputs": [],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgV4kny1bgy1"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0)\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQUOsWLrbjKv"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Rob2Wsb_l9"
      },
      "outputs": [],
      "source": [
        "agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8AuQNfhYm48A"
      },
      "source": [
        "## 5. Memory\n",
        "\n",
        "Add State to Chains and Agents.\n",
        "\n",
        "Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujwj29G2cDPN"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI, ConversationChain\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "conversation = ConversationChain(llm=llm, verbose=True)\n",
        "\n",
        "conversation.predict(input=\"Hi there!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkKv8n7ZnB2e"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"Can we talk about AI?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4P3zWCmoDST"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"I'm interested in Reinforcement Learning.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9wMttXM-CuPK"
      },
      "source": [
        "## 6. Document Loaders\n",
        "\n",
        "Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into âdocumentsâ - a fancy way of say some pieces of text. This module is aimed at making this easy.\n",
        "\n",
        "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAiISOcboPKR"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import NotionDirectoryLoader\n",
        "\n",
        "loader = NotionDirectoryLoader(\"Notion_DB\")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_zcj8MLDGfQ"
      },
      "source": [
        "## 7. Indexes\n",
        "\n",
        "Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents\n",
        "\n",
        "- Embeddings: An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc.\n",
        "- Text Splitters: When you want to deal with long pieces of text, it is necessary to split up that text into chunks.\n",
        "- Vectorstores: Vector databases store and index vector embeddings from NLP models to understand the meaning and context of strings of text, sentences, and whole documents for more accurate and relevant search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLU79cyCozYl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "  f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGyZXiJZBsov"
      },
      "outputs": [],
      "source": [
        "# Document Loader\n",
        "from langchain.document_loaders import TextLoader\n",
        "loader = TextLoader('./state_of_the_union.txt')\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OklI0xTvp2KE"
      },
      "outputs": [],
      "source": [
        "# Text Splitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skvXSMXHCxyq"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1yCdAhSCi64"
      },
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "#text = \"This is a test document.\"\n",
        "#query_result = embeddings.embed_query(text)\n",
        "#doc_result = embeddings.embed_documents([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R3pT55b-uBJ"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7sRydnlC7rb"
      },
      "outputs": [],
      "source": [
        "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "db = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB7lvDWzDHZy",
        "outputId": "3b0399d0-6c04-4cef-a029-e48cbd41eedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while youâre at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
            "\n",
            "Tonight, Iâd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyerâan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâs top legal minds, who will continue Justice Breyerâs legacy of excellence.\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu-AmhDLEK0h"
      },
      "outputs": [],
      "source": [
        "db.save_local(\"faiss_index\")\n",
        "new_db = FAISS.load_local(\"faiss_index\", embeddings)\n",
        "docs = new_db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K1lGH_g2--Si"
      },
      "source": [
        "## End-to-end example\n",
        "\n",
        "https://github.com/hwchase17/chat-langchain\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
